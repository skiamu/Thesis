\chapter{Asset Class Returns modeling}\label{chpt:assetclass_returns}
	
In this chapter, we address the asset class returns modeling issue. As it was noted in the previous chapter, the \gls{ODAA} algorithm does not depend on a particular distribution of the asset class returns vector $\bm{w}_{k+1}$. However, by looking at (\ref{eq:rec_algo}) we see that we need the explicit analytical form for the density function $p_{f(x,\bm{u}_k,\bm{w}_{k+1})}$. For this reason, we will be dealing exclusively with probability distributions closed under linear combination. In this work, we propose three such distributions:
\begin{itemize}
	\item Gaussian
	\item Gaussian Mixture
	\item Generelized Hyperbolic
\end{itemize}
For each of them, after giving a brief theoretical introduction, we will discuss the model-related features of the \gls{ODAA} algorithm. That is, first we will derive the portfolio value density function $p_{f(x,\bm{u}_k,\bm{w}_{k+1})}$ and secondly, an expression for the \textit{risk} constraint (which also depends on the distribution chosen) will be obtained. Moreover, we assume stationarity, therefore the distribution of $\bm{w}_{k+1}$ will not depend on $k$.
\section{Gaussian model}
The first probability distribution we considered is the Gaussian. 
\begin{definition}[Gaussian random vector]\label{def:gauss_rv}
	A $m$-dimensional random vector $\bm{w} = \begin{bmatrix}w_1,\ldots,w_m\end{bmatrix}^T$ is \textbf{Gaussian} if every linear combination $\sum_{i=0}^{m}u_iw_i = \bm{u}^T \bm{w}$ has a one-dimensional Gaussian distribution.
\end{definition}
Let the asset class returns random vector $\bm{w}_{k+1}$ follow a Gaussian distribution with mean $\bm{\mu}$ and covariance matrix $\bm{\Sigma}$. By definition we have \[x(1 + \bm{u}_k^T \bm{w}_{k+1}) \sim \mathcal{N}\Big(\underbrace{x(1 + \bm{u}_k^T \bm{\mu})}_{\tilde{\mu}}, \underbrace{x^2\bm{u}_k^T \bm{\Sigma} \bm{u}_k}_{\tilde{\sigma}^2}\Big)\]
hence
\begin{equation}
\boxed{p_{f(x,\bm{u}_k,\bm{w}_{k+1})}(z) =  \frac{1}{\sqrt{2\pi}\tilde{\sigma}}\exp\bigg\{ -\frac{1}{2}\frac{(z-\tilde{\mu})^2}{\tilde{\sigma}^2}\bigg\}, \quad z \in \mathbb{R}.}
\end{equation}
 

Let us now introduce the two important concepts of loss function and value-at-risk that we will use to derive the \textit{risk} constraint.
\begin{definition}[loss function]\label{def:loss_function}
	Denoting the value of our portfolio at time $k \in \mathbb{N}$ by $x_{k+1}$, the \textbf{loss function} of the portfolio over the period $[k,k+1]$ is given by \[ L_{k+1}:= -\frac{(x_{k+1}-x_k)}{x_k}= -r_{k+1} = -\bm{u}_k^T \bm{w}_{k+1}.  \]
\end{definition}
\begin{definition}[Value-at-risk]
	Given some confidence level $1-\alpha \in (0,1) $ the \textbf{value-at-risk} ($V@R_{1-\alpha}$) of our portfolio is \[ V@R_{1-\alpha} = \inf\{l\in \mathbb{R} : \mathbb{P}\big(L_{k+1} \leq l \big) \geq 1-\alpha \}. \]
\end{definition}
	

The V@R is a risk measure commonly use by financial institutions to assess the risk they run to carry a portfolio of risky securities for a specified period of time (the portfolio must be kept constant during this time period). For instance, if our portfolio has an (\textit{ex-post}) weekly $V@R_{0.99} = 7\%$, this means that $99\%$ of the times our portfolio did not suffer a loss greater or equal than $7\%$ over the investment period. In our case, we receive the V@R specification  as input (\textit{ex-ante} value-at-risk) by the investor (it is an indicator of its risk-aversion) and we will construct an asset allocation $\bm{u}_k$ that satisfies this risk constraint at each $k \in \mathbb{N}$.

Using definition (\ref{def:gauss_rv}) we have \[ L_{k+1} \sim \mathcal{N}\big(\underbrace{-\bm{u}_k^T \bm{\mu}}_{\mu_p},\underbrace{\bm{u}_k^T \bm{\Sigma} \bm{u}_k}_{\sigma^2_p} \big)\] therefore
\begin{align*}
\mathbb{P}\big(L_{k+1} \leq V@R_{1-\alpha}\big) 
& = \mathbb{P}\Big(Z \leq \frac{V@R_{1-\alpha} - \mu_p}{\sigma_p}  \Big) \\
& = 1 - \alpha
\end{align*}
\begin{equation}\label{eq:var_const_gaussian}
\implies \boxed{V@R_{1-\alpha} \geq -\bm{u}_k^T\bm{\mu} + z_{1-\alpha} \sqrt{\bm{u}_k^T \bm{\Sigma} \bm{u}_k}}
\end{equation}
where $Z$ is a standard normal random variable and $z_{1-\alpha}$ is the $1-\alpha$ quantile of the standard normal distribution. The \textit{risk} constraint in equation (\ref{eq:var_const_gaussian}), together with the \textit{budget} and \textit{long-only} constraint, define the control input space $U$ which is the feasible set of the constrained optimization problem given in theorem (\ref{thm:rec_algo}) at each $k$.
\section{Gaussian Mixture model}
In this section we present the second asset class returns model, the \textbf{Gaussian Mixture model} (GM). After introducing the GM distribution we will derive the density and the \textit{risk} constraint, as we did for the Gaussian model. We closely follow \cite{BUCKLEY2008}.

The standard assumption that asset returns have a multivariate Gaussian distribution is a reasonable first approximation to reality and it usually has the big advantage of generating analytically tractable theories (e.g. Markowitz Portfolio Theory). However, the Gaussian model does not capture two key asset returns features which are observed, on the contrary, in market real data:
\begin{enumerate}
	\item the skewed (asymmetric around the mean) and leptokurtic (more fat-tailed than the Gaussian) nature of marginal probability density function
	\item the asymmetric correlation between asset returns, that is the tendency of volatilities and correlations to depend on the prevailing market conditions.
\end{enumerate}
To overcome this shortcomings, the \gls{GM} distribution is a validate alternative to the Gaussian model. Loosely speaking, the pdf of a GM random vector is a linear combination of Gaussian pdfs (called Gaussian regimes or mixing components). This closeness to the Normal distribution offers a good trade-off between analytical tractability and parsimony in the number of parameters. By adopting a \gls{GM} model, it is possible to represent protuberances on the probability iso-density contours, as can be seen in Figure \ref{fig:countour_GM}.
\begin{figure}[]
	\centering
	\includegraphics[width=0.7\textwidth]{Images/GMdensity.png}
	\caption{Example of a GM density contour plot with two mixing components.}
	\label{fig:countour_GM}
\end{figure}
To obtain this highly non-linear dependence structure, we would usually need cross-moments of all order; a big advantage of the GM distribution is that its dependence structure is fully and conveniently captured by the means, covariance matrices and weights of each Gaussian regime (as we will see in the following).

Let us begin the more formal introduction on the GM distribution with its definition.
\begin{definition}[GM distribution]
	An $m$-dimensional random vector $\bm{Z}$ has a \textbf{multivariate GM distribution} if its probability density function is of the form
	\[ p_{\bm{Z}}(\bm{z}) = \sum_{i=1}^{n} \lambda_i \varphi_{(\bm{\mu}_i,\bm{\Sigma}_i)}(\bm{z}), \quad \bm{z} \in \mathbb{R}^m, \] 
	where $\varphi_{(\bm{\mu}_i,\bm{\Sigma}_i)}$ is the multivariate Gaussian density with mean vector $\bm{\mu}_i$ and covariance matrix $\bm{\Sigma}_i$ and $\lambda_i$ are positive mixing weights summing to one.	
\end{definition}
The following proposition is crucial for our purposes since it tells us that linear combinations of GM random vector have a one-dimensional GM distribution.
\begin{proposition}\label{prop:GM_lin_comb}
	Linear combinations of GM random vectors follow a univariate GM distribution. In particular, if $\bm{Z} \sim GM$ then $Y=\bm{\theta}^T \bm{Z}$,  $\forall \bm{\theta} \in \mathbb{R}^m$, has a GM distribution with probability density function \[ p_Y(y) = \sum_{i=1}^{n}\lambda_i \varphi_{(\mu_i,\sigma_i^2)}(y),\quad y \in \mathbb{R} \] where
	\[
	\begin{cases}
	\mu_i & = \bm{\theta}^T \bm{\mu}_i \quad i = 1,\ldots,m \\
	\sigma_i^2 & = \bm{\theta}^T \bm{\Sigma}_i \bm{\theta} \quad i = 1,\ldots,m
	\end{cases} \]
\end{proposition}
\begin{proof}
	The \gls{CF} of a \gls{GM} random vector is the linear combination of the \gls{CF} of the Gaussian mixing components. Indeed, 
	\begin{align*}
	\phi_{\bm{Z}}(\bm{u}) &= \mathbb{E}\big[\exp\{i \bm{u}^T \bm{Z}\} \big] = \int_{\mathbb{R}^m}\exp\{i \bm{u}^T \bm{z}\}p_{\bm{Z}}(\bm{z})\mathrm{d}\bm{z} = \\
	& = \int_{\mathbb{R}^m}\exp\{i \bm{u}^T \bm{z}\}\sum_{i=1}^{n}\lambda_i \varphi_{(\bm{\mu}_i,\bm{\Sigma}_i)}(\bm{z})\mathrm{d}\bm{z} = \\
	& = \sum_{i=1}^{n}\lambda_i \phi_{\bm{X}_i}(\bm{u}), \quad \bm{u} \in \mathbb{R}^m
	\end{align*}
	where $\bm{X}_i \sim \mathcal{N}\big(\bm{\mu}_i,\bm{\Sigma}_i\big)$. Therefore, $\forall \bm{\theta} \in \mathbb{R}^m$ we have
	\begin{align*}
	\phi_{\bm{\theta}^T \bm{Z}}(u) & = \mathbb{E}\big[\exp\{iu(\bm{\theta}^T\bm{Z})\}\big] = \mathbb{E}\big[\exp\{i(u\bm{\theta}^T)\bm{Z}\}\big] = 
    \phi_{\bm{Z}}(u\bm{\theta}) = \\
    & = \sum_{i=1}^{n}\lambda_i \phi_{\bm{X}_i}(u\bm{\theta}) = \sum_{i=1}^{n}\lambda_i \exp\{iu\underbrace{\bm{\theta}^T\bm{\mu}_i}_{\mu_i}-\frac{1}{2}u^2\underbrace{\bm{\theta}^T\bm{\Sigma}_i\bm{\theta}}_{\sigma_i^2}\} = \\
	& = \sum_{i=1}^{n}\lambda_i \phi_{\widetilde{X}_i}(u), \quad u \in \mathbb{R}
	\end{align*}
	where $\widetilde{X}_i \sim \mathcal{N}\big(\mu_i,\sigma_i^2 \big)$. Since the CF completely characterizes the distribution (see \cite{jacod2000probability}, theorem 14.1) we have the result.
\end{proof}

\paragraph{Portfolio value density and \textit{risk} constraint}
Suppose the asset class returns vector $\bm{w}_{k+1}$ follow a Gaussian Mixture distribution. We want to compute the density of random variable $f(x,\bm{u}_k,\bm{w}_{k+1}) = x(1 + \bm{u}_k^T\bm{w}_{k+1})$. Thanks to proposition (\ref{prop:GM_lin_comb}), we know that the random variable $\bm{u}_k^T\bm{w}_{k+1}$ follows itself a \gls{GM} (univariate) distribution. Moreover, by integration we easily derive its \gls{CDF}. This allows us to write
\begin{align*}
F_{f(x,\bm{u}_k,\bm{w}_{k+1})}(z) & = \mathbb{P}\big(x(1+\bm{u}_k^T\bm{w}_{k+1})\leq z \big) = F_{x\bm{u}_k^T\bm{w}_{k+1}}(z-x)\\
& = \sum_{i=1}^{n}\lambda_i \Phi\Big(\frac{z - x(1+\bm{u}_k^T\bm{\mu}_i)}{\sqrt{x^2\bm{u}_k^T\bm{\Sigma}_i\bm{u}_k}}\Big), \quad z \in \mathbb{R}
\end{align*}
where $\Phi$ is the standard normal CDF. Differentiating with respect to $z$, we have
\begin{equation}
\boxed{p_{f(x,\bm{u}_k,\bm{w}_{k+1})}(z) = \sum_{i=1}^{n}\lambda_i \varphi_{(\mu_i,\sigma_i^2)}(z), \quad z \in \mathbb{R}}
\end{equation}
where 
\[
\begin{cases}
	\mu_i &= x(1+\bm{u}^T \bm{\mu}_i) \\
	\sigma_i^2 & = x^2\bm{u}^T\bm{\Sigma}_i \bm{u}.
\end{cases}
\]


We now turn to the problem of computing the \textit{risk} constraint under the GM distribution assumption. We will follow two different approaches. Suppose we are given the $V@R_{1-\alpha}$ specification (e.g. $7\%$); by using definition (\ref{def:loss_function}) we have \[ \mathbb{P}\big(L \leq V@R_{1-\alpha} \big) = F_L(V@R_{1-\alpha}) \geq 1-\alpha \] as noted above, the CDF of $L = -\bm{u}^T \bm{w}$ is known, therefore \[\sum_{i=1}^{n}\lambda_i \Phi\Big(\frac{V@R_{1-\alpha} - \mu_i}{\sigma_i}\Big) \geq 1-\alpha \quad \implies \quad\]
\begin{equation}
 \boxed{\sum_{i=1}^{n}\lambda_i \Phi\Big(-\Big\{\frac{V@R_{1-\alpha} - \mu_i}{\sigma_i} \Big\} \Big) \leq \alpha}  
\end{equation}
where \[
\begin{cases}
\mu_i & = -\bm{u}^T \bm{\mu}_i \\
\sigma_i^2 & = \bm{u}^T \bm{\Sigma}_i \bm{u}.
\end{cases}\]



We present also an alternative method to limit the risk exposure of our portfolio which turns out to be less computationally intensive. The idea is to set an upper bound to portfolio return volatility in the following way 
\begin{equation}\label{eq:risk_upperbnd}
(\Var{r_{k+1}})^{\frac{1}{2}} = (\bm{u}_k^T \bm{\Lambda} \bm{u}_k)^{\frac{1}{2}} \leq \sigma_{max}
\end{equation}
where $\bm{\Lambda}$ is the covariance matrix of vector $\bm{w}_{k+1}$. Two questions are left open: how to compute $\bm{\Lambda}$ and how to link the upper bound $\sigma_{max}$ to the $V@R_{1-\alpha}$ specification given as input by the investor. As far as the former is concerned, the following proposition gives us the answer \cite{BUCKLEY2008}
\begin{proposition}
	The covariance matrix of a random vector with the GM distribution can be expressed in terms of mean vectors, covariance matrices and weights of the mixing components in the following way
	\[ \bm{\Lambda} = \sum_{i=1}^{n}\lambda_i\bm{\Sigma}_i + \sum_{i=1,j<i}^{n,n} \lambda_i\lambda_j(\bm{\mu}_i-\bm{\mu}_j)(\bm{\mu}_i-\bm{\mu}_j)^T.\]
\end{proposition}
To answer the latter, we use a Guassian approximation and the fact that, if the rebalancing frequency is relatively small (e.g. weekly), the portfolio return mean is negligible. In the end, we obtain
\[ \sigma_{max} = \frac{V@R_{1-\alpha}}{z_{1-\alpha}}. \] 
\section{Generelized Hyperbolic model}
The last distribution we propose is the \gls{GH}. Like the \gls{GM}, in its general form also the \gls{GH} presents a non-elliptical behavior with asymmetric and fat-tailed marginals. We proceed to give the formal definition and then derive the density of $f(x,\bm{u}_k,\bm{w}_{k+1})$
and the expression of the \textit{risk} constraint. References for this section are \cite{Brey2013} and \cite{McNeil2005}.
\begin{definition}[GH distribution]\label{def:GH}
	A $m$-dimensional random vector $\bm{X}$ is said to follow a \textbf{multivariate GH distribution} ($\bm{X} \sim GM_m(\lambda,\chi,\psi,\bm{\mu},\bm{\Sigma},\bm{\gamma})$) if \[ \bm{X} = \bm{\mu}+W\bm{\gamma}+\sqrt{W}A\bm{Z} \] where 
	\begin{itemize}
		\item $\bm{Z} \sim \mathcal{N}\big(\bm{0},I_d\big)$
		\item $A \in \mathbb{R}^{m \times d} $ is the Cholesky factor of dispersion matrix $\bm{\Sigma}$ ($A^TA = \bm{\Sigma}$)
		\item $\bm{\mu}, \bm{\gamma} \in \mathbb{R}^m$
		\item $W \sim \mathcal{N}^-(\lambda,\chi,\psi)$, $W \geq 0$ and $W \perp \bm{Z}$ (see Appendix \ref{app:B} for the definition of the \gls{GIG} distribution). $W$ is called mixing random variable.
	\end{itemize}
\end{definition}
\begin{remark}
	\begin{itemize}
		\item $\lambda,\chi,\psi$ are shape parameters; the larger these parameters the closer the distribution is to the Gaussian
		\item $\bm{\gamma}$ is the skewness parameter. If $\bm{\gamma}= \bm{0}$ the distribution is symmetric around the mean
		\item $\bm{X}\lvert W = w \sim \mathcal{N}\big(\bm{\mu}+w\bm{\gamma},w\bm{\Sigma}\big)$.
	\end{itemize}
\end{remark}
The GH distribution contains some special cases:
\begin{itemize}
	\item If $\lambda=\frac{m+1}{2}$ we have a \textit{Hyperbolic} distribution
	\item If $\lambda=-\frac{1}{2}$ the distribution is called \textit{Normal Inverse Gaussian} (NIG)
	\item If $\chi = 0$ and $\lambda > 0$ we have the limiting case of the \textit{Variance Gamma} (VG) distribution
	\item If $\psi = 0$ and $\lambda < 0$ the resulting distribution is called \textit{Student-t}.
\end{itemize}
	
The following proposition gives us the closeness under linear transformation that we need for our modeling purposes
\begin{proposition}
	If $\bm{X} \sim GH_m(\lambda,\chi,\psi,\bm{\mu},\bm{\Sigma},\bm{\gamma})$ and $\bm{Y}=B\bm{X}+\bm{b}$, where $B \in \mathbb{R}^{d\times m}$ and $\bm{b} \in \mathbb{R}^d$, then
	\[ \bm{Y} \sim GH_d(\lambda,\chi,\psi,B\bm{\mu}+\bm{b},B\bm{\Sigma}B^T,B\bm{\gamma}). \]
\end{proposition}
Suppose $\bm{w}_{k+1} \sim GH_m(\lambda,\chi,\psi,\bm{\mu},\bm{\Sigma},\bm{\gamma})$. Applying the previous result to our case, namely $Y = f(x,\bm{u}_k, \bm{w}_{k+1})$, $B=x\bm{u}_k^T$ and $b = x$, we have \[ f(x,\bm{u}_k,\bm{w}_{k+1}) \sim GH_1(\lambda,\chi,\psi,\underbrace{x(1+\bm{u}_k^T\bm{\mu})}_{\widetilde{\mu}},\underbrace{x^2\bm{u}_k^T\bm{\Sigma}\bm{u}_k}_{\widetilde{\Sigma}},\underbrace{x\bm{u}_k^T\bm{\gamma}}_{\widetilde{\gamma}}) \] and the density reads as (see Appendix  \ref{app:B})
\begin{equation}\label{eq:GHdensity}
\boxed{p_{f(x,\bm{u}_k, \bm{w}_{k+1})}(z) = c \frac{K_{\lambda-\frac{1}{2}}\Big(\sqrt{\big(\chi+\widetilde{Q}(z) \big)\big(\psi+\widetilde{\gamma}^2/\widetilde{\Sigma} \big)}\Big)\exp\big\{(z-\widetilde{\mu})\widetilde{\gamma}/\widetilde{\Sigma} \big\}}{\Big(\sqrt{\big(\chi+\widetilde{Q}(z) \big)\big(\psi+\widetilde{\gamma}^2/\widetilde{\Sigma} \big)}\Big)^{\frac{1}{2}-\lambda}}}
\end{equation}
where \[ c = \frac{\big(\sqrt{\chi\psi}\big)^{-\lambda}\psi^{\lambda}\big(\psi+\widetilde{\gamma}^2/\widetilde{\Sigma}\big)^{\frac{1}{2}-\lambda}}{(2\pi\widetilde{\Sigma})^{\frac{1}{2}}K_{\lambda}(\sqrt{\chi\psi})} \]
and $\widetilde{Q}(z)= (z-\widetilde{\mu})/\widetilde{\Sigma}$.


As far as the \textit{risk} constraint is concerned, we adopt here the alternative approach expressed in Equation (\ref{eq:risk_upperbnd}). The covariance matrix $\bm{\Lambda}$ is easily derived from Definition \ref{def:GH} and Equation (\ref{eq:GIG_moment}); in the end we obtain
\begin{equation}
\bm{\Lambda} = \Var{W}\bm{\gamma}\bm{\gamma}^T+\mathbb{E}[W]\bm{\Sigma}
\end{equation}
where
\begin{align*}
\mathbb{E}[W] & = \Big(\frac{\chi}{\psi}\Big)^{\frac{1}{2}}\frac{K_{\lambda+1}(\sqrt{\chi\psi})}{K_{\lambda}(\sqrt{\chi\psi})}\\
\Var{W} & = \Big(\frac{\chi}{\psi}\Big)\frac{1}{K_{\lambda}(\sqrt{\chi\psi})}\Big\{K_{\lambda+2}(\sqrt{\chi\psi})-\frac{K_{\lambda+1}^2(\sqrt{\chi\psi})}{K_{\lambda}(\sqrt{\chi\psi})} \Big\}.
\end{align*}



